<!DOCTYPE html>
<html lang="en">
<head>
	<link href="bibliography.css" rel="stylesheet" type="text/css">
	<link href="https://fonts.googleapis.com/css?family=Lato|Work+Sans" rel="stylesheet">
	<link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
	<script src="editPage.js">
	</script>
	<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.8.3/jquery.min.js">
	</script>
	<title>Bibliography - K. Dewsnap</title>
</head>
<body onload="dateAndEdits()">
	<div id="main">
		<div id="sidebar">
			<p><a href="#vessonen">Vessonen, E. (2017).</a> Psychometrics versus Representational Theory of Measurement.</p>
			<hr>
			<p><a href="#humphry">Humphry, S. M. (2017).</a> Psychological measurement: Theory, paradoxes, and prototypes.</p>
			<hr>
			<p><a href="#mcclimans">McClimans, L. (2017).</a> Health Measurement, Industry, and Science.</p>
			<hr>
			<p><a href="#kaminski">Kaminski, A. (2017).</a> Measuring Intelligence effectively: Psychometrics from a Philosophy of Technology Perspective.</p>
			<hr>
			<p><a href="#michell">Michell, J. (2008).</a> Is Psychometrics Pathological Science?</p>
			<hr>
			<p><a href="#alexandrova">Alexandrova, A. (2017).</a> Is Well-Being Measurable?</p>
			<hr>
			<p><a href="#angner">Angner, E. (2010).</a> Current Trends in Welfare Measurement.</p>
			<hr>
			<p><a href="#borsboom">Borsboom, D. &amp; Mellenbergh, G (2004).</a> Why Psychometrics is not Pathological.</p>
			<hr>
			<p><a href="#maul">Maul, A. (2013).</a> On the ontotology of psychological attributes.</p>
            		<hr>
			<p><a href="#newton">Newton, Paul &amp; Shaw, Stuart (2014).</a> The continued search for nonarbitrary metrics in psychology.</p>
           	 	<hr>
			<p><a href="#embretson">Embretson S. (2006)</a> The continued search for nonarbitrary metrics in psychology.</p>
           	 	<hr>
			<p><a href="#mcclimans2">McLimans, L. (2017).</a> Psychological Measures, Risk, and Values</p>
            		<hr>
            		<p><a href="#cupples">Cupples, L. (2017).</a> The Epistemological Roles of Models in Health Science Measurement</p>
            		<hr>
		</div><!--sidebar-->
		<div id="content">
			<div id="header">
				<h1>Bibliography</h1>
				<h3 id="lastup">x</h3><button id="editToggle" onclick="editButton()">Edit</button> <button onclick="download()">Download Edits</button>
				<hr>
			</div><!--header-->
			<div id="material">
				<div class="head">
					<div class="bib">
						<h4 id="vessonen">Vessonen, E. (2017). Psychometrics versus Representational Theory of Measurement. <i>Philosophy of the Social Sciences, 47</i> (4-5): 330-350. <a class="paper" href="http://journals.sagepub.com/doi/abs/10.1177/0048393117705299" target="_blank">doi:10.1177/0048393117705299</a></h4>
					</div>
					<div class="buttons">
                        <a href="downloads/vessonen2017.pdf" target="_blank" class="button"><i class="material-icons">file_download</i></a>
					</div>
				</div>
				<p class="content" contenteditable="false">Vessonen's paper argues that it is possible to simultaneously endorse both psychometrics and the representational theory of measurement (RTM). She first establishes her position by arguing that RTM and psychometrics have distinct sources of validity. RTM measurements posses representational interpretability, which is the mirroring of the measured construct's empirical structure to the numeric structure of the instrument of measure. Psychometric measures must have procedural validity, which is present when multiple determinations of the target construct form theoretical expectations that cohere with the measurment's results. Vessonen then iterates that RTM does not address measurement's need for procedural validity – RTM says nothing about how to build a construct-valid measurement procedure. Conversely, psychometricians tend to assume the validity of the scales they use, rather than establishing representational interpretability by mirroring their scales against the empirical relationships within the construct. As both theories are partial approaches that deal with different measurement conditions, Vessonen argues that embracing both theories simultaneously is not only possible but can yield fruitful results for researchers.</p>
				<p class="content" contenteditable="false">The paper is built as a charitable critique of <a href="#angner">Angner (2011)</a>, that argues for the incompatibility between RTM and psychometrics. Substantial definitions are given to each term by the author at its introduction. Similar to <a href="#humphry">Humphry (2017)</a>, the author believes that RTM is an incomplete theory of measurement. Interestingly, this author establishes psychometrics as its own measurement theory, contradictory to Borsboom (2005).</p>
				<hr>
                <div class="head">
					<div class="bib">
						<h4 id="humphry">Humphry, S. M. (2017). Psychological measurement: Theory, paradoxes, and prototypes. <i>Theory &amp; Psychology 27</i>(3):407-418. <a class="paper" href="http://journals.sagepub.com/doi/abs/10.1177/0959354317699099" target="_blank">doi:10.1177/0959354317699099</a></h4>
					</div>
					<div class="buttons">
                        <a href="downloads/humphry2017.pdf" target="_blank" class="button"><i class="material-icons">file_download</i></a>
					</div>
				</div>
				<p class="content" contenteditable="false">This article is a critique of the improper use of the term 'theory' by different psychological measurement methodologies. Humphry first defines theory as the theoretical framework used to explain specific phenomena. With this definition established, Humphries critiques item response theory (IRT) and the representational theory of measurement (RTM) for not being true 'theories' – these models only prescribe which strict conditions are required for measurement, and does not explain how scientific theories can support said measure. The author later establishes that as IRT and RTM do not account for measurement's need to be supported by 'substantive theory', these models are partial and quasi-empirical. He ends by establishing a substantive theory of measurement, and warns psychometricians that psychological measurement cannot be possible unless psychologists develop substantive theories that can be used to develop well-defined units of measurement.</p>
				<p class="content" contenteditable="false">The author structures his article as a critique of Joel Michell's "The Rasch Paradox, Conjoint Measurement and Psychometrics" (2014) (which critiqued Humphry's earlier work) as well as strongly supporting RTM as a complete theory. Humphry uses the historical defintion of the metre as a certain number of wavelengths of a specific frequency of light to demonstrate how substantive theories can be useful in building methods of measurement. The author does not define some of the the key terms he uses, such as RTM, IRT, and Rasch models.</p>
				<hr>
                <div class="head">
					<div class="bib">
						<h4 id="mcclimans">McClimans, L. (2017). Health Measurement, Industry, and Science. <i>Philosophical Issues in Pharmaceutics: Development, Dispensing, and Use.</i> (pp. 93-105). Dordrecht: Springer Netherlands.</h4>
					</div>
					<div class="buttons">
                        <a href="downloads/humphry2017.pdf" target="_blank" class="button"><i class="material-icons">file_download</i></a>
                        <a href="https://link.springer.com/chapter/10.1007/978-94-024-0979-6_6/fulltext.html" class="button" target="_blank"><i class="material-icons">link</i></a>
					</div>
				</div>
				<p class="content" contenteditable="false">The paper criticises the metrological foundations of Patient-reported outcome measures (PROMs) and offers suggestions that address her critiques. The author starts by claiming that, as PROMs are based on classical test theory (CTT), PROMs lack a theory of measurement interaction that demonstrates the relationship between the target construct and the instrument of measure (e.g.: a questionnaire). This leads to problems with validity, interpretability, and responsiveness. Consequently, McClimans suggests that psychometricians exercise Rasch methodology to build a theory of measurement interaction. Rasch does this by creating a mathematical model that builds empirical relationships between items and subjects. Although McClimans does believe that PROMs can be improved with Rasch methodologies, she also warns that one should apply Rasch models with strong theoretical guidance to build adequate sensitivity in the model.</p>
                <p class="content" contenteditable="false">McClimans defines Rasch methodology similarly to how Borsboom (2005) defines the representational measurement model. Her critique of CTT is congruent with Vesonnen's critique of Psychometrics. Namely, both models lack a justification for their use of an integer scale to represent their data. McClimans states a belief similar to <a href="#vessonen">Vesonnen (2017)</a>, and <a href="#humphry">Humphry (2017)</a>, saying that theoretically established units of change are necessary in order to build a quantitative scale - something that both CTT and psychometrics do not do.</p>
				<hr>
                <div class="head">
					<div class="bib">
                        <h4 id="kaminski">Kaminski, A. (2017). Measuring Intelligence effectively: Psychometrics from a Philosophy of Technology Perspective. In A. Nordmann &amp; N. Moeßner (Eds.), <i>Reasoning in Measurement</i> (pp. 146-157). London: Routledge.</h4>
					</div>
					<div class="buttons">
                        <a href="downloads/kaminski2017.pdf" target="_blank" class="button"><i class="material-icons">file_download</i></a>
					</div>
				</div>
				<p class="content" contenteditable="false">Kaminski's paper is a critique of the philosophy of science's treatment of psychometrics and argues that they should also focus on justifying why the measurement has seen so much technical success. Kaminski first starts his argument by highlighting that, no matter the critique of psychometrics, each critique fails to recognise that psychometrics has had useful social consequences. The author then suggests that comparisons between classical measurements and mental measurements fail to recognise that applications of psychometrics involve a subject that is aware of its own measurement. This explains psychometrics' success as a technical application; psychometrics are tools that create self-relation in a subject, which has great personal and social consequences. The importance of self-relation is shown by examining psychometrics as a direct cause of the Lynn-Flynn Effect.</p>
				<p class="content" contenteditable="false">This paper strongly suggests that an approach from the philosophy of science is insufficient to build a charitable critique of psychometrics - one must also approach it from a philosophy of technological perspective. This implies that the critique that psychometrics offers an incomplete model of measurement (see: <a href="#vessonen">Vessonen (2017)</a>, <a href="#mcclimans">McClimans (2017)</a>) should be considered alongside evidence that demonstrates the social success of psychometrics. Further pieces that criticise psychometrics from the philosophy of technology would be an excellent supplement to this piece.</p>
				<hr>
                <div class="head">
					<div class="bib">
						<h4 id="michell">Michell, J. (2008). Is Psychometrics Pathological Science? <i>Measurement: Interdisciplinary Research and Perspectives 6</i> (1-2), 7-24. <a class="paper" href="http://statmath.wu.ac.at/courses/r-se-mbr/dl/Michell_Psychometrics_Pathology_2008.pdf" target="_blank">doi:10.1080/15366360802035489</a></p>
					</div>
					<div class="buttons">
                        <a href="downloads/michell2008.pdf" target="_blank" class="button"><i class="material-icons">file_download</i></a>
					</div>
				</div>
				<p class="content" contenteditable="false">This paper is an effort to establish psychometrics as pathological science. The author first defines the pathology of science as the collective failure of a field to recognise its own prejudice that ultimately prevents true science from taking place. Psychometrics is considered pathological as it refuses to recognise that it assumes that mental qualities are quantitative. The author suggests that this pathology was created out of ideological and economic interests to make psychology a 'valid science'. The paper also critiques more modern attempts to remove the pathology from psychometrics, such as the item response model (ITM), as it too ultimately ignores that the data produced by this model is ordinal, and not quantitative. The paper ends with the author suggesting what steps would be necessary to prove that mental measures provide quantitative (and not just ordinal) information, which would 'depathologise' the rest of the measurement field.</p>
				<p class="content" contenteditable="false">This paper is a destructive critique of psychometrics, with Michell calling it a 'quasi-empirical' field. This critique can be found in constructive forms (see <a href="#vessonen">Vessonen (2017)</a> and <a href="#kaminski">Kaminski (2017)</a>). This suggests that psychometrics should be not be viewed as a complete model of measurement, as it does not rely on empirical evidence in order to establish itself as a valid measurment model.</p>
				<hr>
                <div class="head">
					<div class="bib">
						<h4 id="alexandrova">Alexandrova, A. (2017). Is Well-Being Measurable? In <i>A Philosophy for the Science of Well-Being</i>. New York: Oxford University Press.</h4>
					</div>
					<div class="buttons">
                        <a href="downloads/alexandrova2017.pdf" target="_blank" class="button"><i class="material-icons">file_download</i></a>
                        <a href="http://www.oxfordscholarship.com/view/10.1093/oso/9780199300518.001.0001/oso-9780199300518-chapter-5" class="button"><i class="material-icons" target="_blank">link</i></a>
					</div>
				</div>
				<p class="content" contenteditable="false">This chapter argues that the measurement of well-being is possible, even though well-being cannot be measured on an individual level. This article defines well-being as an ‘inclusive good’ that is influenced by a collection of ‘relevant goods’ (e.g. happiness, positive relationships, etc.). As an individuals’ well-being is self-defined, the well-being of individuals is heterogenous, and is impractical to be measured by one measure (i.e. one questionnaire). However, more generalised types of well-being, such as the “well-being of kinds [of individuals]”, can be measured. This is because: (1) by constraining the definition of well-being to mean a certain collection of relative goods that pertain to a kind, its measurement becomes less heterogenous, and; (2) as the relative goods that make up well-being are measurable constructs, a measure of well-being can be compared against said constructs, giving the measure construct validity.</p>
				<p class="content" contenteditable="false">The author is a variantist – she believes that measured constructs can vary in substance and focus. This view makes (1) possible; variantism supports the belief that there are different forms of well-being. The author also claims that construct validity makes psychometrics a valid form of measurement, similarly to how representational theory makes physical measurement valid.</p>
				<hr>
                <div class="head">
					<div class="bib">
						<h4 id="angner">Angner, E. (2010). Current Trends in Welfare Measurement. In J. B. Davis &amp; D. W. Hands (Eds.), <i>The Elgar Companion to Recent Economic Methodology</i>: Edward Elgar Publishing.</h4>
					</div>
					<div class="buttons">
                        <a href="downloads/angner2010.pdf" target="_blank" class="button"><i class="material-icons">file_download</i></a>
                        <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1680053#" class="button" target="_blank"><i class="material-icons">link</i></a>
					</div>
				</div>
				<p class="content" contenteditable="false">Angner’s paper argues that, as subjective measures of well-being become more popular with policy makers and economists, the methodology of well-being measurement is shifting from a measurement-theoretic (i.e. representational) approach to a psychometric approach. The paper first establishes that ‘orthodox economic measurements’ (e.g. measures of GDP, surplus/deficit, etc.) rely on measurement-theoretical models, which creates a homomorphism that links observable items (such as economic choices and states) to a transitive and associative numeric scale. The author then compares this to the measurement of subjective well-being, such as measures of a population's overall happiness. These measures use a psychometric approach, which makes the measurment of an unobservable latent variable (like well-being) possible. The author completes his paper by stating that, as the two approaches treat data and evidence in fundamentally different ways, the two approaches are incompatible.</p>
				<p class="content" contenteditable="false">This paper precedes and motivates the arguments made in <a href="#vessonen">Vessonen (2017)</a>. While both authors agree that a measure made using one approach cannot be valid in the other, Vessonen argues that this does not mean the simultaneous endorsement of the two approaches is inconsistent. This paper also compliments <a href="#kaminski">Kaminski (2017)</a>, as the two both address the socioeconomic usefulness of the psychometric approach.</p>
				<hr>
		<div class="head">
					<div class="bib">
                        <h4 id="borsboom">Borsboom, D., &amp; Mellenbergh, G. J. (2004). Why Psychometrics is Not Pathological: A Comment on Michell. <i>Theory &amp; Psychology, 14</i>(1), 105-120. <a href="http://journals.sagepub.com/doi/abs/10.1177/0959354304040200#articleCitationDownloadContainer" target="_blank">doi:10.1177/0959354304040200</a><p></h4>
					</div>
					<div class="buttons">
                        <a href="downloads/borsboom2004.pdf" target="_blank" class="button"><i class="material-icons">file_download</i></a>
					</div>
				</div>
				<p class="content" contenteditable="false">Borsboom and Mellenbergh’s paper argues that Michell’s critiques of psychometrics in his 2008 paper “Is Psychometrics a Pathological Science” are not relevant to item-response theories of measurement (IRTs). As psychological tests can only provide probabilistic data, the authors state that this data cannot be analysed with a deterministic model, such as the fundamental/representational theory of measurement. To conduct measurement with probabilistic data, psychometricians loosen this fundamental theory by hypothesising that a latent variable (i.e. the target construct) is the main cause of variation between test scores. The introduction of a latent variable allows for an item-response function to be built by studying the effects of attribute factors and item factors, ultimately making measurement possible.</p>
				<p class="content" contenteditable="false">The authors believe that failed IRFs are falsified because they rely on false assumptions. As a latent hypothesis is one of the assumptions that an IRT model makes, and assumptions are never falsified in isolation (as per the Quine-Duhem thesis), the authors believe that psychometricians do not empirically test the latent hypothesis because it is impossible to test, not because it is “blindly accepted as true” as <a href="#michell">Michell (2008)</a> suggests. The authors concede that Michell’s critiques are applicable to classical test theory, as the classical test theory is not a model, but a tautology.</p>
				<hr>
		<div class="head">
					<div class="bib">
                        <h4 id="maul">Maul, A. (2013). On the ontology of psychological attributes. <i>Theory &amp; Psychology, 23</i>(6), 752-769. <a href="http://journals.sagepub.com/doi/abs/10.1177/0959354313506273#articleCitationDownloadContainer" target="_blank">doi:10.1177/0959354313506273</a><p></h4>
					</div>
					<div class="buttons">
                        <a href="downloads/maul2013.pdf" target="_blank" class="button"><i class="material-icons">file_download</i></a>
					</div>
				</div>
				<p class="content" contenteditable="false">In response to the popularisation of scientific realist philosophy within psychometrics, Maul’s paper attempts to establish what it means to be a realist regarding psychological attributes. The author first defines that a realist commitment within psychology would result in one believing in mind-independent psychological attributes. Maul then attempts to justify that such a commitment is consistent, by first establishing that one can gather epistemically objective (conscious-independent, e.g. observations of neurological activity) accounts of ontologically subjective events (conscious-dependant, e.g. pain). This leads one to the supervenience of psychological attributes over neurological events; one cannot undergo a change in psychological states without changes in neurological physiology. Therefore, when one takes a realist position towards psychological attributes, one believes that these attributes are emergent and irreducible features of neurobiological mechanisms.</p>
                		<p class="content" contenteditable="false">This paper discusses what it means to be a psychological realist, which is relevant to the positions of many psychometricians and philosophers of science. <a href="#michell">Michell (2008)</a> and <a href="#borsboom">Borsboom &amp; Mellenbergh (2004)</a> are both papers published by realists, and both believe that a realist commitment is necessary to conduct psychometric measurement. The paper also discusses why realist commitments are pragmatic to psychometricians, which compliments the variantist view taken by <a href="#alexandrova">Alexandrova (2017).</a></p>
				<hr>
		<div class="head">
					<div class="bib">
			<h4 id="newton">Newton, P. E., &amp; Shaw, S. D. (2014). Validity and Validation. In <i>Validity in educational &amp; psychological assessment</i> (pp. 1-25). Los Angeles: SAGE.</h4>
					</div>
					<div class="buttons">
                        <a href="downloads/newton2014.PDF" target="_blank" class="button"><i class="material-icons">file_download</i></a>
                        <a href="http://mcgill.worldcat.org/title/validity-in-educational-psychological-assessment/oclc/880912474&referer=brief_results" class="button" target="_blank"><i class="material-icons">link</i></a>
					</div>
				</div>
                <p class="content" contenteditable="false">Newton and Shaw’s first chapter of their book <u>Validity in Education &amp; Psychological Assessment</u> introduces both the concept of psycho-educational measurement validity, and the history of the concept’s establishment. The authors first demonstrate that validity carries many different context-dependant definitions, and then warns us that measurement validity is a unique type of validity that is not synonymous with research validity. After the chapter defines the different types of validity that have been used in recent philosophical discourse (e.g.: ‘construct’, ‘criterion’, and ‘content’ validity), the chapter then gives a brief overview of the history of psychometric validity, from the mid-1800s to the present day.</p>
                <p class="content" contenteditable="false">This chapter strives to narrow down its definition of the word ‘validity’ to a definition relevant to the scope of the book, which focuses on the applications of the concept of validity in the educational and psychological fields. The chapter’s historical introduction shows how construct validity, a core component of psychometric models (see <a href="#vessonen">Vessonen [2017]</a>, <a href="#mcclimans">McClimans [2017]</a>, &amp; <a href="#angner">Angner [2010]</a>), first emerged as one of many ‘types’ of validity, then was deemed to be the unitary source of validity in psychological and educational tests. This unitary view has been recently dismantled, in favour of adopting a deconstructed model of validity that can be evaluated more manageably.</p>
				<hr>
		<div class="head">
					<div class="bib">
			<h4 id="embretson">Embretson, S. E. (2006). The continued search for nonarbitrary metrics in psychology. <i>Am Psychol, 61</i>(1), 50-55; discussion 62-71. <a href="https://www.ncbi.nlm.nih.gov/pubmed/16435976" target="_blank">doi:10.1037/0003-066x.61.1.50</a></h4>
					</div>
					<div class="buttons">
                        <a href="downloads/embretson2006.pdf" target="_blank" class="button"><i class="material-icons">file_download</i></a>
					</div>
				</div>
                <p class="content" contenteditable="false">This paper continues the work of psychologists Blanton and Jaccard (2006), by discussing what would be necessary to create nonarbitrary metrics in psychology, as well as the effects of arbitrary metrics on statistical analysis. The paper defines arbitrary measurement as all measurement that uses a metric system whose locations of observed scores (i.e., whether they are high or low) or the meaning of one unit-change is unknown. As universal metrics (with true zero points and interval widths) are incompatible with accepted notions of psychological constructs, the author suggests that psychologists instead use model-based measurements (like IRT) to define the relative distances between scores, as well as linking scores to test-items and external data.</p>
                <p class="content" contenteditable="false">Embretson also believes that the use of arbitrary metrics in psychology affects how researchers interpret their data. This stems from the use of parametric statistics on arbitrary measurement, which can lead to researchers observing spurious interactions between raw scores and a latent variable. This aligns with the concerns of <a href="#humphry">Humphry (2017)</a>: the lack of substantive theories in psychology prevents the field from using well-defined units of measure, which ultimately devalues the representational integrity of psychometric tools.</p>
				<hr>
		<div class="head">
					<div class="bib">
		<h4 id="mcclimans2">McClimans, L. (2017). Psychological Measures, Risk, and Values. In L. McClimans (Ed.), <i>Measurement in Medicine: Philosophical Essays on Assessment and Evaluation</i> (pp. 89-105). Lanham Rowman &amp; Littlefield International.</h4>
					</div>
					<div class="buttons">
                        <a href="chapters/chapter6.pdf" target="_blank" class="button"><i class="material-icons">file_download</i></a>
					</div>
				</div>
                <p class="content" contenteditable="false">The sixth chapter of Measure in Medicine discusses how the strict realism insisted upon by modern psychometricians unfairly discounts the importance of nonepistemic ethical values when using psychometrics in medicine and research. McClimans starts with discussing the forms of conflicting realist views held by <a href="#borsboom">Borsboom (2004)</a> and <a href="#michell">Michell (2008)</a>. While both psychometricians are entity realists, the two disagree on how this realism must manifest itself in psychometric models. However, McClimans notes that this debate focusses solely on the importance of epistemic values (like rigor and truth) when selecting a measurement model.</p>
                <p class="content" contenteditable="false">McClimans takes issue with this strict realism; she believes that it obscures the importance of nonepistemic ethical values, such as truth and harm, in selecting psychometric measures. As with any medical or research practice, psychometricians should bear in mind that the results of psychometric tests strongly influence the lives of those tested. The author then states that both the traditional classical test theory and the recently-popularised latent variable model struggle with these questions, leading to measurements that do not account for their ethical implications. Complimentary to this point, <a href="#alexandrova">Alexandrova (2017)</a> states that the issues that arise in building valid measures of well-being stem from the individual variations of the concept’s definition.</p>
                		<hr>
                <div class="head">
					<div class="bib">
		<h4 id="cupples">Cupples, L. M. (2017). The Epistemological Roles of Models in Health Science Measurement. In L. McClimans (Ed.), <i>Measurement in Medicine: Philosophical Essays on Assessment and Evaluation</i> (pp. 107-120). Lanham Rowman &amp; Littlefield International.</h4>
					</div>
					<div class="buttons">
                        <a href="chapters/chapter7.pdf" target="_blank" class="button"><i class="material-icons">file_download</i></a>
					</div>
				</div>
                <p class="content" contenteditable="false">Cupples provides an account of how validity, comparability, and accuracy in patient recorded outcome measures (PROMs) can be established with qualitative, statistical, and theoretical models, respectfully. Cupples first demonstrates that PROMs are complex measures that rely on many different processes such as patient understanding of test items, the conceptual content of the target concept, and error management. To ensure that the understanding of a target concept is consistent between test subjects and examiners, the author suggests that content validity can be established by incorporating qualitative research into the creation of PROMs. Comparability between measures of the same construct can be established by using statistical modelling to demonstrate consistency between different operations of measurement. Finally, Cupples stresses the importance of using theoretical models to ensure that error phenomena, like response shift, are accounted for when evaluating PROMs.</p>
                <p class="content" contenteditable="false">This paper is an attempt to apply the concept of operational accuracy within psychometrics; the empirical data from a PROM should be consistent with idealised theoretical predictions. However, the author states that there is a lack of theoretical modelling within psychology, preventing the pursuit of said operational accuracy. This echoes the concerns of <a href="#humphry">Humphry (2017)</a>, as he believes that psychology requires substantive theories in order to build valid psychometric models.</p>
				<hr>
		<div class="head">
					<div class="bib">
						<h4 id="weschler">Weschler, D. (1997). Cognitive, conative, and non-intellective intelligence. In J. M. Notterman (Ed.), <i>The evolution of psychology : fifty years of the American psychologist</i> (pp. 22-32). Washington: American Psychological Association.<p></h4>
					</div>
					<div class="buttons">
                        <a href="downloads/wechsler_1950.pdf" target="_blank" class="button"><i class="material-icons">file_download</i></a>
                        <a href="http://mcgill.worldcat.org/title/evolution-of-psychology-fifty-years-of-the-american-psychologist/oclc/37615844&referer=brief_results" class="button"><i class="material-icons" target="_blank">link</i></a>
					</div>
				</div>
				<p class="content" contenteditable="false">David Wechsler presents the idea that intelligence is not simply a reflection of one’s intellectual ability, but instead a manifestation of one’s personality. The lecture begins with a brief history of psychology’s conceptualisation of intelligence as one’s ability to deal with their environment. While this ability is influenced by one’s intellectual skills (e.g. reasoning, verbal, spatial, and numeric aptitude), it is not wholly determined by these components. Wechsler suggests that intelligence is also a product of “non-intellective factors” that are made up of personality components. As a result, Wechsler states that psychologists must reconceptualise intelligence and intelligence tests with a more wholistic interpretation.</p>
                <p class="content" contenteditable="false">Wechsler uses two methods to support the idea of intelligence as a product of personality. First, he cites that psychologists have historically taken issue with the concept of intelligence as pure intellectual ability. This is particularly seen in Thorndike’s  breakdown of intelligence into abstract, social, and practical components. Second, Wechsler establishes factor analysis as a measurement of external validity (see: <a href="#newton">Newton &amp; Shaw [2008]</a>), and then shows that the factor analysis of intelligence against intellectual skills only explains 60% of the variance between intelligence test scores. The rest of the variation can be attributed to personality traits like an individual’s interests or their temperament towards achievement (see <a href="http://psycnet.apa.org/record/1936-05157-001" target="_blank">Alexander [1935]</a>).</p>
                <hr>
                <div class="head">
					<div class="bib">
						<h4 id="coalson">Coalson, D. L., Raiford, S. E., Saklofske, D. H., &amp; Weiss, L. G. (2010). CHAPTER 1 - WAIS-IV: Advances in the Assessment of Intelligence. In <i>WAIS-IV Clinical Use and Interpretation</i> (pp. 3-23). San Diego: Academic Press.<p></h4>
					</div>
					<div class="buttons">
                        <a href="downloads/coalson2010.pdf" target="_blank" class="button"><i class="material-icons">file_download</i></a>
                        <a href="http://www.sciencedirect.com.proxy3.library.mcgill.ca/science/article/pii/B9780123750358100011" class="button"><i class="material-icons" target="_blank">link</i></a>
					</div>
				</div>
				<p class="content" contenteditable="false">Click <a href="downloads/NPGP_The%20WAIS-IV.pdf" target="_blank">here</a> for a summary, and <a href="downloads/NPGP_WAIS-IV%20Subtests.pdf">here</a> for a table of the subtests on the WAIS-IV.</p>
				<hr>
                <div class="head">
					<div class="bib">
						<h4 id="flynn">Flynn, J. R. (1987). Massive IQ gains in 14 nations: What IQ tests really measure. <i>Psychological Bulletin, 101</i>(2), 171-191. doi:10.1037/0033-2909.101.2.171<p></h4>
					</div>
					<div class="buttons">
                        <a href="downloads/flynn_1987.pdf" target="_blank" class="button"><i class="material-icons">file_download</i></a>
                        <a href="http://psycnet.apa.org/record/1987-17534-001" class="button"><i class="material-icons" target="_blank">link</i></a>
					</div>
				</div>
				<p class="content" contenteditable="false">James Flynn, American psychologist, presents data from 165 scholars on the intergenerational differences in IQ scores, and hypothesises that these differences demonstrate that intelligence tests do not measure intelligence, but instead measure a weak corollary of it (abstract problem-solving ability [APSA]). The data came from 35 developed nations, and was presented as the average scores that different generations (from the same demographic) received on the same intelligence tests (culturally-reduced [e.g. Raven’s Matrices], combined [e.g. Wechsler tests], and purely verbal). The data was analysed on a per-country basis and then was given a rank, which indicates to what extent the data verifies the existence of massive IQ gains between generations. As per Flynn, the results of his analysis show that “no psychologist in any part of the developed world can discount the possibility of massive gains,” with a median intergenerational gain of fifteen IQ points.</p>
                <p class="content" contenteditable="false">This data brought Flynn to adopt these hypotheses: (1) learned content on IQ tests inhibits IQ growth, as score gain was the most extreme on culturally-reduced tests; (2) these IQ gains are not due to the population’s IQ peaking at an earlier age, as indirect and direct evidence show that gains persist to full maturation; (3) data suggests that the Ravens Progressive Matrices Test measures a correlate with a weak causal link to intelligence, and that other intelligence tests may measure the same; (4) massive IQ gains in Netherlands have been caused by unidentified environmental variables, and; (5) that between-group score differences on IQ tests may not be equivalent to between-group intelligence differences.</p>
                <hr/>
			</div><!--material-->
		</div><!--content-->
	</div><!--main->
</body>
</html>
	  
